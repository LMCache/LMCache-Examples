{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMCache Introduction\n",
    "LMCache is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Serving without KV cache hit\n",
    "Give an example of long document QA without KV cache hit. Turn vLLM prefix caching off and do long wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Serving with KV cache hit\n",
    "Give an example of long document QA without KV cache hit. Turn vLLM prefix caching off and use LMCache long wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens in real life without LMCache\n",
    "setup: vllm with prefix cache on\n",
    "\n",
    "Show two scenarios, each scenario will contain 2 requests.\n",
    "1. second request right after first request, prefix cache was hit. fast\n",
    "2. after first request, many other user queries come in and flushed out the original KV cache. (Add a visualization in notebook that many queries came in and evicts the KV cache from GPU memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens with LMCache\n",
    "\n",
    "setup: vllm with LMCache\n",
    "\n",
    "Show use of the sa\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
